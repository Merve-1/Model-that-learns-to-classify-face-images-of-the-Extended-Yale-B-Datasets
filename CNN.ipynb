{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7wmO6bDIwZQ"
      },
      "source": [
        "## **Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dW7AdL--G8iX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import datasets, layers, models, losses\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "import pandas as pd\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7ixs_ZIVKuxB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw2PCyq3SzVZ",
        "outputId": "3c15221f-29e9-43ae-d0f0-490815a1ea63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVM7RGd9Jt7W"
      },
      "source": [
        "## **Loading dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeuTN5xHJGsD"
      },
      "outputs": [],
      "source": [
        "#connection to my drive\n",
        "path =\"/content/drive/My Drive/ExtendedYaleB\"\n",
        "#images list\n",
        "images = []\n",
        "#labels list\n",
        "labels = []\n",
        "\n",
        "#loop over images folders\n",
        "for i in range(1, 39):\n",
        "    if i < 10:\n",
        "        subdirPath = os.path.join(path, f'yaleB0{i}')\n",
        "    #folder 14 doesnot exist\n",
        "    elif i == 14:\n",
        "        subdirPath = os.path.join(path, f'yaleB{i+1}')\n",
        "        i = i +1\n",
        "    else:\n",
        "        subdirPath = os.path.join(path, f'yaleB{i}')\n",
        "    #loop over each file images\n",
        "    for filename in os.listdir(subdirPath):\n",
        "        #some folders doesnot contain images only so this if conditon to loop over images only\n",
        "        if filename.endswith('.pgm'):\n",
        "            imgPath = os.path.join(subdirPath, filename)\n",
        "            img = cv2.imread(imgPath, cv2.IMREAD_GRAYSCALE)\n",
        "            # Resize the image to 64x64\n",
        "            img = cv2.resize(img, (64, 64))\n",
        "            images.append(img)\n",
        "            # Extract the label from the filename and append it to the labels list\n",
        "            label = int(filename.split(\"_\")[0][-2:]) - 1\n",
        "            labels.append(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlYGivi0x7fQ"
      },
      "outputs": [],
      "source": [
        "#list conversion into array\n",
        "listToArray = np.array(images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7AUmXsqv_Sc"
      },
      "source": [
        "## **Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcqFzcdPKx4X"
      },
      "outputs": [],
      "source": [
        "#split the dataset into training 80%, validation 10%, and testing 10% sets\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(listToArray,labels,test_size=0.1)\n",
        "x_train, x_val,y_train, y_val = train_test_split(x_train,y_train,test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aigM8fm_Yw5v"
      },
      "outputs": [],
      "source": [
        "#changing the range to be between [0,1]\n",
        "x_train = x_train / 255.0\n",
        "x_val = x_val / 255.0\n",
        "x_test = x_test/ 255.0\n",
        "# converting the values to be numpy array\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "y_test = np.array(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping the dataset\n",
        "x_train = x_train.reshape((-1, 64, 64, 1))\n",
        "x_val = x_val.reshape((-1, 64, 64, 1))\n",
        "x_test = x_test.reshape((-1, 64, 64, 1))"
      ],
      "metadata": {
        "id": "-FgaQmxQQe2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQIfnixl6MoR"
      },
      "source": [
        "## **MLP Buliding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydNpBIh33wCe"
      },
      "outputs": [],
      "source": [
        "# Build a Multilayer Perceptron model\n",
        "mlpModel = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(64, 64)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(38, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z8Dp3Az7B6h",
        "outputId": "d97a489f-ed5b-4ed6-9af8-0cf834e46b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_30 (Flatten)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 128)               524416    \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 38)                2470      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,142\n",
            "Trainable params: 535,142\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "mlpModel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CNN Building**"
      ],
      "metadata": {
        "id": "0FJXSj2W84Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a Convolutional Neural Network (CNN) model\n",
        "cnnModel = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(38, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "b2RWjcmG9Bln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnnModel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQQi4-En99e4",
        "outputId": "956c0d0b-95df-4e05-8d59-28f101ad35a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_27 (Conv2D)          (None, 62, 62, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 31, 31, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 6, 6, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_31 (Flatten)        (None, 4608)              0         \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 512)               2359808   \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 38)                19494     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,471,974\n",
            "Trainable params: 2,471,974\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Fk-pL66k5-"
      },
      "source": [
        "## **Set Loss Function & Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71kKL9MmzBJ7"
      },
      "outputs": [],
      "source": [
        "# Sparse Categorical loss function is used because w have a wide range of labels\n",
        "mlpModel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sparse Categorical loss function is used because w have a wide range of labels\n",
        "cnnModel.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "fZCsaFy--L9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G675hWoc7b6t"
      },
      "source": [
        "## **Train model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training with the defult batch size (32) and 30 ephocs\n",
        "history = mlpModel.fit(x_train, y_train, epochs=30 , validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCLTAnoS-pvr",
        "outputId": "76dadc3c-aec4-4f01-d69c-2ef21321fd07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "62/62 [==============================] - 2s 13ms/step - loss: 3.6004 - accuracy: 0.0464 - val_loss: 3.4536 - val_accuracy: 0.0769\n",
            "Epoch 2/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.1266 - accuracy: 0.1991 - val_loss: 2.8390 - val_accuracy: 0.2443\n",
            "Epoch 3/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.3175 - accuracy: 0.4375 - val_loss: 1.8923 - val_accuracy: 0.6154\n",
            "Epoch 4/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.5928 - accuracy: 0.6517 - val_loss: 1.3420 - val_accuracy: 0.7421\n",
            "Epoch 5/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.1496 - accuracy: 0.7510 - val_loss: 0.9421 - val_accuracy: 0.8462\n",
            "Epoch 6/30\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.8196 - accuracy: 0.8422 - val_loss: 0.7588 - val_accuracy: 0.8643\n",
            "Epoch 7/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6460 - accuracy: 0.8841 - val_loss: 0.6767 - val_accuracy: 0.8552\n",
            "Epoch 8/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5235 - accuracy: 0.9153 - val_loss: 0.5297 - val_accuracy: 0.9140\n",
            "Epoch 9/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4230 - accuracy: 0.9340 - val_loss: 0.4054 - val_accuracy: 0.9276\n",
            "Epoch 10/30\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.3467 - accuracy: 0.9491 - val_loss: 0.3600 - val_accuracy: 0.9276\n",
            "Epoch 11/30\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.3029 - accuracy: 0.9567 - val_loss: 0.3294 - val_accuracy: 0.9457\n",
            "Epoch 12/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.2586 - accuracy: 0.9637 - val_loss: 0.3208 - val_accuracy: 0.9321\n",
            "Epoch 13/30\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.2193 - accuracy: 0.9733 - val_loss: 0.2269 - val_accuracy: 0.9683\n",
            "Epoch 14/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.1877 - accuracy: 0.9763 - val_loss: 0.2067 - val_accuracy: 0.9729\n",
            "Epoch 15/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.1756 - accuracy: 0.9773 - val_loss: 0.2281 - val_accuracy: 0.9367\n",
            "Epoch 16/30\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.1543 - accuracy: 0.9798 - val_loss: 0.1818 - val_accuracy: 0.9683\n",
            "Epoch 17/30\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.1296 - accuracy: 0.9844 - val_loss: 0.1606 - val_accuracy: 0.9729\n",
            "Epoch 18/30\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.1235 - accuracy: 0.9849 - val_loss: 0.1643 - val_accuracy: 0.9774\n",
            "Epoch 19/30\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.1101 - accuracy: 0.9874 - val_loss: 0.1519 - val_accuracy: 0.9683\n",
            "Epoch 20/30\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.1001 - accuracy: 0.9874 - val_loss: 0.1491 - val_accuracy: 0.9774\n",
            "Epoch 21/30\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.0898 - accuracy: 0.9874 - val_loss: 0.1314 - val_accuracy: 0.9729\n",
            "Epoch 22/30\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.0845 - accuracy: 0.9884 - val_loss: 0.1263 - val_accuracy: 0.9819\n",
            "Epoch 23/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.0774 - accuracy: 0.9889 - val_loss: 0.1097 - val_accuracy: 0.9819\n",
            "Epoch 24/30\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.0717 - accuracy: 0.9884 - val_loss: 0.1009 - val_accuracy: 0.9819\n",
            "Epoch 25/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.0668 - accuracy: 0.9899 - val_loss: 0.1058 - val_accuracy: 0.9774\n",
            "Epoch 26/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.0633 - accuracy: 0.9909 - val_loss: 0.1068 - val_accuracy: 0.9774\n",
            "Epoch 27/30\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.0601 - accuracy: 0.9914 - val_loss: 0.0982 - val_accuracy: 0.9819\n",
            "Epoch 28/30\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.0561 - accuracy: 0.9919 - val_loss: 0.1058 - val_accuracy: 0.9683\n",
            "Epoch 29/30\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.0629 - accuracy: 0.9894 - val_loss: 0.1067 - val_accuracy: 0.9819\n",
            "Epoch 30/30\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.1619 - accuracy: 0.9617 - val_loss: 0.7423 - val_accuracy: 0.7783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MmcvtB16zuT",
        "outputId": "1890e601-c5cb-493a-ff24-5b9a3a23690c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "62/62 [==============================] - 19s 281ms/step - loss: 3.6266 - accuracy: 0.0449 - val_loss: 3.5919 - val_accuracy: 0.0732\n",
            "Epoch 2/30\n",
            "62/62 [==============================] - 19s 308ms/step - loss: 3.5333 - accuracy: 0.0685 - val_loss: 3.3942 - val_accuracy: 0.1423\n",
            "Epoch 3/30\n",
            "62/62 [==============================] - 18s 290ms/step - loss: 2.8688 - accuracy: 0.2172 - val_loss: 1.8891 - val_accuracy: 0.5325\n",
            "Epoch 4/30\n",
            "62/62 [==============================] - 17s 276ms/step - loss: 1.6002 - accuracy: 0.5509 - val_loss: 0.9792 - val_accuracy: 0.7439\n",
            "Epoch 5/30\n",
            "62/62 [==============================] - 17s 281ms/step - loss: 1.0134 - accuracy: 0.6976 - val_loss: 0.6434 - val_accuracy: 0.8496\n",
            "Epoch 6/30\n",
            "62/62 [==============================] - 17s 280ms/step - loss: 0.5956 - accuracy: 0.8196 - val_loss: 0.4041 - val_accuracy: 0.8984\n",
            "Epoch 7/30\n",
            "62/62 [==============================] - 17s 279ms/step - loss: 0.3876 - accuracy: 0.8846 - val_loss: 0.3000 - val_accuracy: 0.9350\n",
            "Epoch 8/30\n",
            "62/62 [==============================] - 19s 313ms/step - loss: 0.2925 - accuracy: 0.9088 - val_loss: 0.2289 - val_accuracy: 0.9472\n",
            "Epoch 9/30\n",
            "62/62 [==============================] - 17s 277ms/step - loss: 0.2334 - accuracy: 0.9335 - val_loss: 0.2134 - val_accuracy: 0.9634\n",
            "Epoch 10/30\n",
            "62/62 [==============================] - 17s 280ms/step - loss: 0.1926 - accuracy: 0.9410 - val_loss: 0.1735 - val_accuracy: 0.9675\n",
            "Epoch 11/30\n",
            "62/62 [==============================] - 17s 281ms/step - loss: 0.1818 - accuracy: 0.9481 - val_loss: 0.1680 - val_accuracy: 0.9634\n",
            "Epoch 12/30\n",
            "62/62 [==============================] - 17s 281ms/step - loss: 0.1372 - accuracy: 0.9551 - val_loss: 0.1460 - val_accuracy: 0.9715\n",
            "Epoch 13/30\n",
            "62/62 [==============================] - 19s 300ms/step - loss: 0.1349 - accuracy: 0.9612 - val_loss: 0.1511 - val_accuracy: 0.9756\n",
            "Epoch 14/30\n",
            "62/62 [==============================] - 18s 291ms/step - loss: 0.1058 - accuracy: 0.9677 - val_loss: 0.1576 - val_accuracy: 0.9715\n",
            "Epoch 15/30\n",
            "62/62 [==============================] - 18s 283ms/step - loss: 0.0775 - accuracy: 0.9773 - val_loss: 0.1458 - val_accuracy: 0.9715\n",
            "Epoch 16/30\n",
            "62/62 [==============================] - 17s 281ms/step - loss: 0.0740 - accuracy: 0.9763 - val_loss: 0.1410 - val_accuracy: 0.9756\n",
            "Epoch 17/30\n",
            "62/62 [==============================] - 17s 277ms/step - loss: 0.0685 - accuracy: 0.9814 - val_loss: 0.1323 - val_accuracy: 0.9756\n",
            "Epoch 18/30\n",
            "62/62 [==============================] - 17s 280ms/step - loss: 0.0686 - accuracy: 0.9778 - val_loss: 0.1297 - val_accuracy: 0.9756\n",
            "Epoch 19/30\n",
            "62/62 [==============================] - 19s 311ms/step - loss: 0.0654 - accuracy: 0.9808 - val_loss: 0.1377 - val_accuracy: 0.9756\n",
            "Epoch 20/30\n",
            "62/62 [==============================] - 17s 280ms/step - loss: 0.0558 - accuracy: 0.9834 - val_loss: 0.1688 - val_accuracy: 0.9756\n",
            "Epoch 21/30\n",
            "62/62 [==============================] - 17s 277ms/step - loss: 0.0698 - accuracy: 0.9788 - val_loss: 0.1597 - val_accuracy: 0.9756\n",
            "Epoch 22/30\n",
            "62/62 [==============================] - 17s 283ms/step - loss: 0.0601 - accuracy: 0.9808 - val_loss: 0.1523 - val_accuracy: 0.9756\n",
            "Epoch 23/30\n",
            "62/62 [==============================] - 17s 280ms/step - loss: 0.0535 - accuracy: 0.9844 - val_loss: 0.1538 - val_accuracy: 0.9756\n",
            "Epoch 24/30\n",
            "62/62 [==============================] - 19s 302ms/step - loss: 0.0675 - accuracy: 0.9793 - val_loss: 0.1665 - val_accuracy: 0.9715\n",
            "Epoch 25/30\n",
            "62/62 [==============================] - 18s 291ms/step - loss: 0.0673 - accuracy: 0.9768 - val_loss: 0.1391 - val_accuracy: 0.9756\n",
            "Epoch 26/30\n",
            "62/62 [==============================] - 17s 281ms/step - loss: 0.0442 - accuracy: 0.9879 - val_loss: 0.1519 - val_accuracy: 0.9715\n",
            "Epoch 27/30\n",
            "62/62 [==============================] - 17s 281ms/step - loss: 0.0552 - accuracy: 0.9834 - val_loss: 0.1473 - val_accuracy: 0.9756\n",
            "Epoch 28/30\n",
            "62/62 [==============================] - 17s 281ms/step - loss: 0.0465 - accuracy: 0.9859 - val_loss: 0.1574 - val_accuracy: 0.9756\n",
            "Epoch 29/30\n",
            "62/62 [==============================] - 17s 279ms/step - loss: 0.0463 - accuracy: 0.9874 - val_loss: 0.1411 - val_accuracy: 0.9797\n",
            "Epoch 30/30\n",
            "62/62 [==============================] - 19s 312ms/step - loss: 0.0471 - accuracy: 0.9844 - val_loss: 0.1760 - val_accuracy: 0.9756\n"
          ]
        }
      ],
      "source": [
        "# Model training with the defult batch size (32) and 30 ephocs\n",
        "history = cnnModel.fit(x_train, y_train, epochs=30, validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluate model**"
      ],
      "metadata": {
        "id": "G1P6hYZliCxk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aJsR7x38C4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53334069-8d83-4c0d-e168-f8dbe5f9ce29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9942 - accuracy: 0.7358\n"
          ]
        }
      ],
      "source": [
        "mlpLoss, mlpAcc = mlpModel.evaluate(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnnLoss, cnnAcc = cnnModel.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRrQ_8Ppia2-",
        "outputId": "4053ee9b-8ed0-4a07-d79b-35d9cfa59c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 59ms/step - loss: 0.1760 - accuracy: 0.9756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bonus**"
      ],
      "metadata": {
        "id": "Jh5HBQSm5yNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data augmentation**"
      ],
      "metadata": {
        "id": "iH0vUKwH53Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataAugmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.03),\n",
        "    #layers.RandomTranslation(height_factor = (-0.2,1), width_factor = (-0.2,1), fill_mode =\"reflect\"),\n",
        "    layers.RandomContrast(factor=(0.1,0.2),seed=None),\n",
        "])"
      ],
      "metadata": {
        "id": "i4d4-ayX21b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MLP With Data augmentation**"
      ],
      "metadata": {
        "id": "brEjNrqT8WRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a Multilayer Perceptron Model With Data Augmentation\n",
        "mlpModelAug = tf.keras.models.Sequential([\n",
        "    dataAugmentation,\n",
        "    tf.keras.layers.Flatten(input_shape=(64, 64)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(38, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "0I0vLbs88hiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training/Testing the model\n",
        "mlpModelAug.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the MLP model on the training set (with data augmentation), default batch size and 30 epochs\n",
        "mlpHistoryAug = mlpModelAug.fit(x_train, y_train, epochs=30 , validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the MLP model on the testing set (with data augmentation)\n",
        "mlpLossAug, mlpAccAug = mlpModelAug.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYD4CAue31zB",
        "outputId": "53177fae-24a6-4a30-9592-6543c4bdb36d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "62/62 [==============================] - 3s 20ms/step - loss: 3.6667 - accuracy: 0.0413 - val_loss: 3.5652 - val_accuracy: 0.0588\n",
            "Epoch 2/30\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 3.4618 - accuracy: 0.0897 - val_loss: 3.2644 - val_accuracy: 0.1629\n",
            "Epoch 3/30\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 3.1436 - accuracy: 0.1578 - val_loss: 2.8067 - val_accuracy: 0.2398\n",
            "Epoch 4/30\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 2.8132 - accuracy: 0.2298 - val_loss: 2.5089 - val_accuracy: 0.2941\n",
            "Epoch 5/30\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 2.4861 - accuracy: 0.3100 - val_loss: 2.1586 - val_accuracy: 0.3982\n",
            "Epoch 6/30\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 2.1213 - accuracy: 0.4229 - val_loss: 1.7096 - val_accuracy: 0.4842\n",
            "Epoch 7/30\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 1.8775 - accuracy: 0.4909 - val_loss: 1.5555 - val_accuracy: 0.5792\n",
            "Epoch 8/30\n",
            "62/62 [==============================] - 1s 24ms/step - loss: 1.6540 - accuracy: 0.5549 - val_loss: 1.3860 - val_accuracy: 0.6244\n",
            "Epoch 9/30\n",
            "62/62 [==============================] - 2s 25ms/step - loss: 1.4926 - accuracy: 0.5993 - val_loss: 1.2537 - val_accuracy: 0.6697\n",
            "Epoch 10/30\n",
            "62/62 [==============================] - 2s 24ms/step - loss: 1.3644 - accuracy: 0.6391 - val_loss: 1.1351 - val_accuracy: 0.6787\n",
            "Epoch 11/30\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 1.2541 - accuracy: 0.6603 - val_loss: 1.1714 - val_accuracy: 0.6561\n",
            "Epoch 12/30\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 1.2081 - accuracy: 0.6568 - val_loss: 0.9971 - val_accuracy: 0.7376\n",
            "Epoch 13/30\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 1.1159 - accuracy: 0.6915 - val_loss: 0.9229 - val_accuracy: 0.7647\n",
            "Epoch 14/30\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 1.0165 - accuracy: 0.7308 - val_loss: 0.9549 - val_accuracy: 0.7240\n",
            "Epoch 15/30\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.9518 - accuracy: 0.7273 - val_loss: 0.8885 - val_accuracy: 0.7602\n",
            "Epoch 16/30\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.9154 - accuracy: 0.7465 - val_loss: 0.7832 - val_accuracy: 0.8100\n",
            "Epoch 17/30\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.8445 - accuracy: 0.7671 - val_loss: 0.7937 - val_accuracy: 0.7511\n",
            "Epoch 18/30\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.7885 - accuracy: 0.7908 - val_loss: 0.7027 - val_accuracy: 0.8145\n",
            "Epoch 19/30\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 0.7593 - accuracy: 0.7823 - val_loss: 0.6739 - val_accuracy: 0.8054\n",
            "Epoch 20/30\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 0.7111 - accuracy: 0.8054 - val_loss: 0.6320 - val_accuracy: 0.8190\n",
            "Epoch 21/30\n",
            "62/62 [==============================] - 2s 25ms/step - loss: 0.7026 - accuracy: 0.8024 - val_loss: 0.6259 - val_accuracy: 0.8371\n",
            "Epoch 22/30\n",
            "62/62 [==============================] - 2s 25ms/step - loss: 0.6530 - accuracy: 0.8191 - val_loss: 0.5828 - val_accuracy: 0.8326\n",
            "Epoch 23/30\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.6429 - accuracy: 0.8145 - val_loss: 0.5886 - val_accuracy: 0.8326\n",
            "Epoch 24/30\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.6186 - accuracy: 0.8160 - val_loss: 0.5416 - val_accuracy: 0.8371\n",
            "Epoch 25/30\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 0.5514 - accuracy: 0.8518 - val_loss: 0.4806 - val_accuracy: 0.8462\n",
            "Epoch 26/30\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 0.5488 - accuracy: 0.8412 - val_loss: 0.4983 - val_accuracy: 0.8507\n",
            "Epoch 27/30\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.5145 - accuracy: 0.8589 - val_loss: 0.4786 - val_accuracy: 0.8914\n",
            "Epoch 28/30\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 0.4948 - accuracy: 0.8654 - val_loss: 0.4209 - val_accuracy: 0.8778\n",
            "Epoch 29/30\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 0.4551 - accuracy: 0.8816 - val_loss: 0.4257 - val_accuracy: 0.8914\n",
            "Epoch 30/30\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.4642 - accuracy: 0.8684 - val_loss: 0.4114 - val_accuracy: 0.8824\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.8780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CNN with data augmentation**"
      ],
      "metadata": {
        "id": "AqFgkB1V6AWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnnModelAug = Sequential([\n",
        "    dataAugmentation,\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(38, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "dwJsSoo234aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training/Testing the model\n",
        "cnnModelAug.compile(optimizer=\"adam\", loss=losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
        "# Train the CNN model on the training set (with data augmentation)\n",
        "cnnHistoryAug = cnnModelAug.fit(x_train, y_train,epochs=30, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the CNN model on the testing set (with data augmentation)\n",
        "cnnLossAug, cnnAccAug = cnnModelAug.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qEg_uX69z01",
        "outputId": "b457aac4-fdb7-4bac-c912-89a1f45ee723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "62/62 [==============================] - 19s 283ms/step - loss: 3.6231 - accuracy: 0.0484 - val_loss: 3.6116 - val_accuracy: 0.0407\n",
            "Epoch 2/30\n",
            "62/62 [==============================] - 22s 349ms/step - loss: 3.5659 - accuracy: 0.0529 - val_loss: 3.4475 - val_accuracy: 0.0543\n",
            "Epoch 3/30\n",
            "62/62 [==============================] - 18s 296ms/step - loss: 3.1457 - accuracy: 0.1578 - val_loss: 2.5454 - val_accuracy: 0.3529\n",
            "Epoch 4/30\n",
            "62/62 [==============================] - 17s 283ms/step - loss: 2.3702 - accuracy: 0.3523 - val_loss: 1.6670 - val_accuracy: 0.5385\n",
            "Epoch 5/30\n",
            "62/62 [==============================] - 18s 283ms/step - loss: 1.7116 - accuracy: 0.4985 - val_loss: 1.0526 - val_accuracy: 0.7014\n",
            "Epoch 6/30\n",
            "62/62 [==============================] - 17s 282ms/step - loss: 1.3135 - accuracy: 0.6028 - val_loss: 0.7080 - val_accuracy: 0.8416\n",
            "Epoch 7/30\n",
            "62/62 [==============================] - 18s 290ms/step - loss: 1.0617 - accuracy: 0.6694 - val_loss: 0.4446 - val_accuracy: 0.9095\n",
            "Epoch 8/30\n",
            "62/62 [==============================] - 19s 307ms/step - loss: 0.9191 - accuracy: 0.7359 - val_loss: 0.3839 - val_accuracy: 0.9050\n",
            "Epoch 9/30\n",
            "62/62 [==============================] - 18s 285ms/step - loss: 0.7758 - accuracy: 0.7631 - val_loss: 0.2793 - val_accuracy: 0.9548\n",
            "Epoch 10/30\n",
            "62/62 [==============================] - 18s 284ms/step - loss: 0.6521 - accuracy: 0.7984 - val_loss: 0.1792 - val_accuracy: 0.9548\n",
            "Epoch 11/30\n",
            "62/62 [==============================] - 17s 280ms/step - loss: 0.5618 - accuracy: 0.8256 - val_loss: 0.1595 - val_accuracy: 0.9638\n",
            "Epoch 12/30\n",
            "62/62 [==============================] - 18s 285ms/step - loss: 0.5222 - accuracy: 0.8407 - val_loss: 0.1027 - val_accuracy: 0.9729\n",
            "Epoch 13/30\n",
            "62/62 [==============================] - 19s 311ms/step - loss: 0.4745 - accuracy: 0.8589 - val_loss: 0.1369 - val_accuracy: 0.9774\n",
            "Epoch 14/30\n",
            "62/62 [==============================] - 18s 284ms/step - loss: 0.4592 - accuracy: 0.8589 - val_loss: 0.0904 - val_accuracy: 0.9774\n",
            "Epoch 15/30\n",
            "62/62 [==============================] - 18s 285ms/step - loss: 0.3964 - accuracy: 0.8700 - val_loss: 0.0810 - val_accuracy: 0.9774\n",
            "Epoch 16/30\n",
            "62/62 [==============================] - 18s 288ms/step - loss: 0.3456 - accuracy: 0.8942 - val_loss: 0.0789 - val_accuracy: 0.9864\n",
            "Epoch 17/30\n",
            "62/62 [==============================] - 18s 285ms/step - loss: 0.3749 - accuracy: 0.8821 - val_loss: 0.0605 - val_accuracy: 0.9910\n",
            "Epoch 18/30\n",
            "62/62 [==============================] - 20s 322ms/step - loss: 0.3282 - accuracy: 0.9007 - val_loss: 0.0569 - val_accuracy: 0.9819\n",
            "Epoch 19/30\n",
            "62/62 [==============================] - 18s 292ms/step - loss: 0.3139 - accuracy: 0.9042 - val_loss: 0.0511 - val_accuracy: 0.9910\n",
            "Epoch 20/30\n",
            "62/62 [==============================] - 18s 286ms/step - loss: 0.2763 - accuracy: 0.9183 - val_loss: 0.0485 - val_accuracy: 0.9910\n",
            "Epoch 21/30\n",
            "62/62 [==============================] - 17s 281ms/step - loss: 0.2913 - accuracy: 0.9153 - val_loss: 0.0501 - val_accuracy: 0.9864\n",
            "Epoch 22/30\n",
            "62/62 [==============================] - 18s 299ms/step - loss: 0.2520 - accuracy: 0.9239 - val_loss: 0.0403 - val_accuracy: 0.9819\n",
            "Epoch 23/30\n",
            "62/62 [==============================] - 19s 297ms/step - loss: 0.2875 - accuracy: 0.9153 - val_loss: 0.0495 - val_accuracy: 0.9864\n",
            "Epoch 24/30\n",
            "62/62 [==============================] - 17s 283ms/step - loss: 0.2609 - accuracy: 0.9173 - val_loss: 0.0543 - val_accuracy: 0.9819\n",
            "Epoch 25/30\n",
            "62/62 [==============================] - 17s 280ms/step - loss: 0.2710 - accuracy: 0.9138 - val_loss: 0.0423 - val_accuracy: 0.9910\n",
            "Epoch 26/30\n",
            "62/62 [==============================] - 18s 286ms/step - loss: 0.2006 - accuracy: 0.9365 - val_loss: 0.0253 - val_accuracy: 0.9955\n",
            "Epoch 27/30\n",
            "62/62 [==============================] - 19s 302ms/step - loss: 0.2341 - accuracy: 0.9269 - val_loss: 0.0348 - val_accuracy: 0.9910\n",
            "Epoch 28/30\n",
            "62/62 [==============================] - 18s 296ms/step - loss: 0.2114 - accuracy: 0.9345 - val_loss: 0.0321 - val_accuracy: 0.9910\n",
            "Epoch 29/30\n",
            "62/62 [==============================] - 18s 285ms/step - loss: 0.1938 - accuracy: 0.9405 - val_loss: 0.0337 - val_accuracy: 0.9864\n",
            "Epoch 30/30\n",
            "62/62 [==============================] - 17s 282ms/step - loss: 0.2129 - accuracy: 0.9355 - val_loss: 0.0336 - val_accuracy: 0.9910\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1308 - accuracy: 0.9756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Displaying the data**"
      ],
      "metadata": {
        "id": "e_z74SE96HN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the table data as a list of lists\n",
        "table_data = [\n",
        "    ['MLP without augmentation', mlpLoss, mlpAcc , np.nan, np.nan],\n",
        "    ['MLP with augmentation', np.nan, np.nan, mlpLossAug, mlpAccAug],\n",
        "    ['CNN without augmentation', cnnLoss, cnnAcc , np.nan, np.nan],\n",
        "    ['CNN with augmentation', np.nan, np.nan, cnnLossAug, cnnAccAug]\n",
        "]\n",
        "\n",
        "# Define the table headers\n",
        "headers = ['Model', 'Loss (without augmentation)', 'Accuracy (without augmentation)', 'Loss (with augmentation)', 'Accuracy (with augmentation)']\n",
        "\n",
        "# Print the table using the tabulate package\n",
        "print(tabulate(table_data, headers=headers))\n",
        "\n"
      ],
      "metadata": {
        "id": "lVZnfoSmys2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0e628e-cafd-4ba9-8f24-2e4e090ab79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model                       Loss (without augmentation)    Accuracy (without augmentation)    Loss (with augmentation)    Accuracy (with augmentation)\n",
            "------------------------  -----------------------------  ---------------------------------  --------------------------  ------------------------------\n",
            "MLP without augmentation                       0.994154                           0.735772                  nan                             nan\n",
            "MLP with augmentation                        nan                                nan                           0.497098                        0.878049\n",
            "CNN without augmentation                       0.176026                           0.97561                   nan                             nan\n",
            "CNN with augmentation                        nan                                nan                           0.130791                        0.97561\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}